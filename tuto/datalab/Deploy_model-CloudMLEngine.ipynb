{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'huiyi-sandbox'\n",
    "PROJECT = 'huiyi-training'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.7' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy trained model\n",
    "\n",
    "Deploying the trained model to act as a REST web service is a simple gcloud call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556264922/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556265520/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556266120/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556266720/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556267320/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556267922/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556268521/\n",
      "gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556268945/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/tuto/trained_model/export/exporter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying tuto_model ml_on_gcp from gs://huiyi-sandbox/tuto/trained_model/export/exporter/1556268945/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/huiyi-training/models/tuto_model].\n",
      "Creating version (this might take a few minutes)......\n",
      ".........................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "#gcloud ml-engine models create tuto_model\n",
    "MODEL_NAME=\"tuto_model\"\n",
    "MODEL_VERSION=\"ml_on_gcp\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/tuto/trained_model/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model to predict (online prediction)\n",
    "\n",
    "Send a JSON request to the endpoint of the service to make it predict a sale price. The order of the responses are the order of the instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [{\"predictions\": [1627683.375], \"key\": [\"a1\"]}, {\"predictions\": [1501837.625], \"key\": [\"a2\"]}]}\n"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "import json\n",
    "\n",
    "MODEL_NAME = 'tuto_model'\n",
    "MODEL_VERSION = 'ml_on_gcp'\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "api = 'https://ml.googleapis.com/v1/projects/{}/models/{}/versions/{}:predict' \\\n",
    "         .format(PROJECT, MODEL_NAME, MODEL_VERSION)\n",
    "\n",
    "headers = {'Authorization': 'Bearer ' + token }\n",
    "data = {\n",
    "  \"instances\": [\n",
    "    {\n",
    "    \"key\": \"a1\", \n",
    "    \"BOROUGH\": \"2\", \n",
    "    \"BLOCK\": 1133.0, \n",
    "    \"ZIP_CODE\": 10099.0\n",
    "    },\n",
    "    {\n",
    "    \"key\": \"a2\", \n",
    "    \"BOROUGH\": \"5\", \n",
    "    \"BLOCK\": 2126.0, \n",
    "    \"ZIP_CODE\": 10175.0\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model to predict (batch prediction)\n",
    "\n",
    "Batch prediction is commonly used when you thousands to millions of predictions. Create a file withe one instance per line and submit using gcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inputs.json\n"
     ]
    }
   ],
   "source": [
    "%writefile inputs.json\n",
    "{\"key\": \"b1\", \"BOROUGH\": \"1\", \"BLOCK\": 1003.0, \"ZIP_CODE\": 11199.0}\n",
    "{\"key\": \"b2\", \"BOROUGH\": \"4\", \"BLOCK\": 2196.0, \"ZIP_CODE\": 10105.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: tutopred_190426_114214\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://inputs.json [Content-Type=application/json]...\n",
      "/ [0 files][    0.0 B/  135.0 B]                                                \r",
      "/ [1 files][  135.0 B/  135.0 B]                                                \r\n",
      "Operation completed over 1 objects/135.0 B.                                      \n",
      "Removing gs://huiyi-sandbox/tuto/batchpred/outputs/prediction.errors_stats-00000-of-00001#1556205802089369...\n",
      "Removing gs://huiyi-sandbox/tuto/batchpred/outputs/prediction.results-00000-of-00001#1556205782831224...\n",
      "/ [1/2 objects]  50% Done                                                       \r",
      "/ [2/2 objects] 100% Done                                                       \r\n",
      "Operation completed over 2 objects.                                              \n",
      "Job [tutopred_190426_114214] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe tutopred_190426_114214\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs tutopred_190426_114214\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "INPUT=gs://${BUCKET}/tuto/batchpred/inputs.json\n",
    "OUTPUT=gs://${BUCKET}/tuto/batchpred/outputs\n",
    "gsutil cp inputs.json $INPUT\n",
    "gsutil -m rm -rf $OUTPUT \n",
    "gcloud ml-engine jobs submit prediction tutopred_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --data-format=TEXT --region ${REGION} \\\n",
    "  --input-paths=$INPUT \\\n",
    "  --output-path=$OUTPUT \\\n",
    "  --model=tuto_model --version=ml_on_gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
